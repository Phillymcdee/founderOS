# Ideas & Validation Domain - Business Process Manual

> **Purpose**: This document explains the business logic, processes, and workflows for the Ideas & Validation domain. It serves as a reference for understanding how the system works from a business perspective, not just code.

---

## Table of Contents

1. [Domain Concepts](#domain-concepts)
2. [Idea State Machine](#idea-state-machine)
3. [Business Rules](#business-rules)
4. [Workflows](#workflows)
5. [Dashboard Metrics](#dashboard-metrics)
6. [Scoring System](#scoring-system)

---

## Domain Concepts

### Core Entities

#### **Idea**
A potential product opportunity that goes through validation.

**Key Fields:**
- `title`: Name of the idea
- `description`: What the idea does
- `icpDescription`: Target customer description (e.g., "Agencies using Gmail")
- `arpuEstimate`: Estimated monthly revenue per user ($)
- `state`: Current lifecycle state (see State Machine section)
- `totalScore`: Aggregated score (1-12) from four dimensions
- `autoGenerated`: Whether created automatically from signals vs. manually

**Relationships:**
- Has many `experiments` (validation tests)
- Has many `sourceSignalIds` (signals that inspired this idea)

#### **IdeaExperiment**
A validation test run on an idea to determine if it's worth pursuing.

**Key Fields:**
- `type`: One of `SIGNAL`, `WORKFLOW`, or `AGENT_OWNERSHIP`
- `description`: What the experiment tests
- `result`: `PENDING`, `PASSED`, `FAILED`, or `INCONCLUSIVE` (nullable)

**Important Distinction:**
- **Experiments are separate records** from idea state
- Moving an idea to `EXPERIMENTING` state does NOT automatically create experiments
- Experiments must be created separately (via "Run experiment loop" or manual logging)

#### **IdeaSignal**
Market/user signals that indicate problems or opportunities.

**Key Fields:**
- `source`: Where the signal came from (e.g., "LinkedIn Jobs", "Reddit", "G2 Reviews")
- `content`: The actual signal text

**Purpose:**
- Signals feed into idea discovery
- Multiple signals can be grouped into a single idea

---

## Idea State Machine

### Valid States

1. **PENDING_REVIEW** - Newly created idea, awaiting initial review
2. **BACKLOG** - Default state for new ideas
3. **SCORING** - Idea is being evaluated/scored
4. **EXPERIMENTING** - Idea is ready for validation experiments
5. **VALIDATED** - Idea passed experiments and is ready to build
6. **KILLED** - Idea failed filters or experiments, not pursuing

### State Transitions

#### Automatic Transitions (via "Auto-score all ideas" or "Discover new ideas")

```
BACKLOG → SCORING → EXPERIMENTING (if totalScore >= minScoreForExperiment)
                  → SCORING (if totalScore < minScoreForExperiment)
                  → KILLED (if fails hard filters)
```

**Hard Filters** (all must pass):
- `passesMarket`: ARPU estimate >= `arpuFloor` (default: $50/month)
- `passesRegulation`: Not in excluded domains (medical, securities, gambling)
- `passesAgentFit`: Not manual work heavy
- `passesFounderFit`: Has founder fit signal

**Scoring Threshold:**
- If `totalScore >= minScoreForExperiment` (default: 9) → `EXPERIMENTING`
- If `totalScore < minScoreForExperiment` → `SCORING`

#### Manual Transitions (via Kanban drag-and-drop or dropdown)

**Any state → Any state** (manual override allowed)

Common manual flows:
- `SCORING` → `EXPERIMENTING` (manually promote high-scoring idea)
- `EXPERIMENTING` → `VALIDATED` (manually validate without experiments)
- `EXPERIMENTING` → `KILLED` (manually kill idea)
- Any state → `KILLED` (kill idea at any point)

#### Automatic Transitions (via Experiment Loop)

```
EXPERIMENTING → VALIDATED (if all experiments PASSED, >=2 experiments, includes AGENT_OWNERSHIP)
             → KILLED (if any experiment FAILED with HIGH confidence)
```

**Experiment Result Logic:**
- If any experiment has `result === 'FAILED'` AND confidence is `HIGH` → `KILLED`
- If all experiments have `result === 'PASSED'` AND count >= 2 AND includes `AGENT_OWNERSHIP` type → `VALIDATED`
- Otherwise, stays in `EXPERIMENTING`

---

## Business Rules

### Top Candidates

**Definition:** Ideas that are actively being validated or have been validated.

**Logic:**
```typescript
ideas.filter(
  idea => idea.state === 'EXPERIMENTING' || idea.state === 'VALIDATED'
)
.sort((a, b) => (b.totalScore ?? 0) - (a.totalScore ?? 0))
.slice(0, 3)
```

**Key Points:**
- Only includes ideas in `EXPERIMENTING` or `VALIDATED` states
- Sorted by `totalScore` (highest first)
- Shows top 3 only
- **Moving an idea to `EXPERIMENTING` makes it a top candidate**

### Active Experiments

**Definition:** All experiment records in the system.

**Logic:**
```typescript
ideas.flatMap(idea => idea.experiments)
```

**Key Points:**
- Counts actual `IdeaExperiment` database records
- Includes ALL experiments from ALL ideas (no filtering by state or result)
- **Does NOT filter by idea state** - experiments from ideas in any state are counted
- **Does NOT filter by experiment result** - includes PENDING, PASSED, FAILED, INCONCLUSIVE

**Important:** Moving an idea to `EXPERIMENTING` does NOT create experiments. The counter will be 0 until experiments are created via:
- "Run experiment loop" button (automatically creates experiments for ideas in `EXPERIMENTING` with no experiments)
- Manual experiment logging

### Experiment Creation

**When are experiments created?**

1. **Automatically** (via "Run experiment loop"):
   - Finds all ideas in `EXPERIMENTING` state
   - For ideas with `experiments.length === 0`:
     - Calls `runExperimentDesignerAgent()` to design experiments
     - Creates experiment records with `result: 'PENDING'`
   - For ideas with pending experiments:
     - Interprets completed experiments
     - Updates idea state based on results

2. **Manually** (via "Log Experiment" action):
   - User manually creates an experiment record
   - Can set type, description, and optional result

**Experiment Types:**
- `SIGNAL`: Tests if market signals validate the idea
- `WORKFLOW`: Tests if the workflow/process is feasible
- `AGENT_OWNERSHIP`: Tests if agents can own this work (required for VALIDATION)

### Experiment Interpretation

**How experiments are evaluated:**

The system uses **LLM-based interpretation** (with automatic keyword-based fallback) to analyze experiment results and determine verdicts.

**Primary Method: LLM Interpretation**
- Uses OpenAI (gpt-4o-mini) or Anthropic (claude-3-5-sonnet) to analyze experiment descriptions
- Understands context, metrics, and nuanced signals
- Provides structured verdicts: `PASSED`, `FAILED`, or `INCONCLUSIVE`
- Includes confidence level (`HIGH`, `MEDIUM`, `LOW`) and reasoning
- Suggests concrete next steps

**Fallback Method: Keyword-Based Logic**
- Automatically used when:
  - No LLM API key is configured
  - LLM API call fails
  - LLM returns invalid structure
- Uses pattern matching on experiment description text
- Less nuanced but still functional

**What the LLM Analyzes:**
- For **SIGNAL tests**: Looks for genuine interest/pain signals (not just polite responses)
- For **WORKFLOW tests**: Looks for measurable value (time saved, errors reduced, quality improved)
- For **AGENT_OWNERSHIP tests**: Looks for successful automation (70%+ handled, <5% error rate, reliable quality)

**Verdict Criteria:**
- **PASSED**: Clear positive signals that validate the idea
- **FAILED**: Clear negative signals that invalidate the idea
- **INCONCLUSIVE**: Mixed signals, insufficient data, or unclear results

**Configuration:**
Set one of these environment variables to enable LLM interpretation:
- `OPENAI_API_KEY=sk-...` (uses gpt-4o-mini by default)
- `ANTHROPIC_API_KEY=sk-ant-...` (uses claude-3-5-sonnet-20241022 by default)

If neither is set, the system automatically falls back to keyword-based interpretation.

---

## Workflows

### Workflow 1: Discover New Ideas

**Trigger:** "Discover new ideas" button (manual) or scheduled cron

**Steps:**
1. **Signal Ingestion** (`runSignalIngestionAgent`)
   - Pulls signals from configured sources (LinkedIn jobs, Reddit, G2 reviews, etc.)
   - Creates `IdeaSignal` records

2. **Problem Mapping** (`runProblemMapperAgent`)
   - Groups related signals into themes
   - Maps themes to clear problem statements
   - Generates idea candidates

3. **Auto-Scoring** (for each candidate)
   - Runs hard filters
   - If passes all filters → calculates scores
   - Sets initial state:
     - `KILLED` if fails hard filters
     - `EXPERIMENTING` if `totalScore >= minScoreForExperiment` (default: 9)
     - `SCORING` if `totalScore < minScoreForExperiment`

4. **Result:** New ideas appear in appropriate Kanban columns

---

### Workflow 2: Auto-Score All Ideas

**Trigger:** "Auto-score all ideas" button

**Steps:**
1. For each idea in `BACKLOG` or `SCORING`:
   - Runs hard filters
   - Calculates scores (if passes filters)
   - Updates state based on `totalScore` vs `minScoreForExperiment`

2. **Result:** Ideas move to appropriate states based on scores

---

### Workflow 3: Run Experiment Loop

**Trigger:** "Run experiment loop" button

**Steps:**
1. **Find Ideas Needing Experiments**
   - Queries all ideas where `state === 'EXPERIMENTING'`
   - Includes their existing experiments

2. **Design Experiments** (for ideas with no experiments)
   - Calls `runExperimentDesignerAgent(idea)`
   - Creates experiment records with:
     - `type`: SIGNAL, WORKFLOW, or AGENT_OWNERSHIP
     - `description`: What to test
     - `result`: 'PENDING'

3. **Interpret Completed Experiments** (for ideas with experiments)
   - Finds experiments where `result !== 'PENDING'` and `result !== null`
   - Calls `runExperimentInterpreterAgent()` for each
   - Uses LLM-based interpretation (with keyword fallback) to analyze experiment results
   - Updates experiment `result` if interpreter has HIGH confidence and different verdict

4. **Update Idea State Based on Results**
   - If any experiment `FAILED` with HIGH confidence → `KILLED`
   - If all experiments `PASSED`, count >= 2, includes `AGENT_OWNERSHIP` → `VALIDATED`
   - Otherwise → stays `EXPERIMENTING`

**Result:** 
- New experiments created for ideas without them
- Idea states updated based on experiment results
- "Active Experiments" counter increases

---

### Workflow 4: Manual Idea Validation

**Trigger:** User drags idea card or changes state dropdown

**Steps:**
1. User selects new state (e.g., `SCORING` → `EXPERIMENTING`)
2. System calls `updateIdeaState(ideaId, newState)`
3. Idea state updated in database
4. Page refreshes to show updated state

**Important:** This does NOT create experiments. User must run "Run experiment loop" separately.

---

## Dashboard Metrics

### Total Ideas
**Definition:** Count of all ideas in the system
**Logic:** `ideas.length`
**Notes:** Includes ideas in all states

### Top Candidates
**Definition:** Count of ideas in `EXPERIMENTING` or `VALIDATED` states
**Logic:** See "Top Candidates" section above
**Display:** Shows top 3, sorted by `totalScore`

### Active Experiments
**Definition:** Count of all experiment records
**Logic:** See "Active Experiments" section above
**Important:** This counts experiment RECORDS, not ideas in `EXPERIMENTING` state

### Signals Processed
**Definition:** Count of `IdeaSignal` records
**Logic:** `signals.length`
**Notes:** Shows total signals ingested, not just signals linked to ideas

---

## Scoring System

### Hard Filters (Must Pass All)

1. **Market Filter** (`passesMarket`)
   - `arpuEstimate >= arpuFloor` (default: $50/month)
   - Idea must have sufficient revenue potential

2. **Regulation Filter** (`passesRegulation`)
   - `regulatedConcern === false`
   - Description doesn't include excluded domains (medical, securities, gambling)

3. **Agent Fit Filter** (`passesAgentFit`)
   - `manualWorkHeavy === false`
   - Idea must be automatable by agents

4. **Founder Fit Filter** (`passesFounderFit`)
   - `founderFitSignal === true`
   - Idea aligns with founder's strengths

**If any filter fails → Idea goes to `KILLED` state**

### Scoring Dimensions (1-3 points each)

1. **Pain Frequency Score** (1-3)
   - Keywords: recurring, weekly, daily, pain, always
   - Measures how often the problem occurs

2. **Agent Leverage Score** (1-3)
   - Counts matches with `agentFitKeywords` (inbox, email, CRM, ticket, document, schedule, summary)
   - Measures how well agents can solve this

3. **Data Surface Score** (1-3)
   - Keywords: email, inbox, CRM, ticket, doc
   - Measures availability of data for agents

4. **Repeatability Score** (1-3)
   - Keywords: workflow, process, monitor, review
   - Measures how repeatable the solution is

**Total Score:** Sum of all four dimensions (4-12 possible)

**State Assignment:**
- `totalScore >= minScoreForExperiment` (default: 9) → `EXPERIMENTING`
- `totalScore < minScoreForExperiment` → `SCORING`

---

## Key Insights & Rationale

### Why LLM-Based Experiment Interpretation

**Design Decision:** Use LLM for experiment interpretation with keyword-based fallback.

**Rationale:**
- **Experiments are narrative data**: Results are written descriptions with metrics, quotes, and context
- **LLMs excel at nuanced analysis**: Can understand mixed signals, weigh multiple factors, and provide context-aware verdicts
- **Low volume, high leverage**: Each experiment is a critical business decision worth a few cents of LLM cost
- **Graceful degradation**: Falls back to keyword-based logic when LLM unavailable (no API key, network issues, etc.)
- **Better than keyword rules**: Handles edge cases like "3 enthusiastic replies from ICP" vs "50 lukewarm likes"

**Trade-offs:**
- **Pros**: Handles nuance, understands context, provides detailed reasoning
- **Cons**: Requires API key, less deterministic than pure rules, small cost per interpretation
- **Mitigation**: Automatic fallback ensures system always works, even without LLM

### Why Experiments Are Separate from State

**Design Decision:** Ideas can be in `EXPERIMENTING` state without having experiments yet.

**Rationale:**
- State indicates **readiness** for experiments
- Experiments are **actual validation work** that needs to be tracked
- Separation allows:
  - Manual control over when experiments are created
  - Tracking experiment history separately from state changes
  - Running experiment loop on schedule vs. on-demand

### Why "Active Experiments" Counts All Experiments

**Current Behavior:** Counts all experiment records, regardless of idea state or experiment result.

**Rationale:**
- Experiments are validation work that happened
- Even if an idea is KILLED, its experiments are still "active" records
- Provides visibility into total validation activity

**Potential Improvement:** Could filter to only experiments from ideas in `EXPERIMENTING` state, or only experiments with `result === 'PENDING'` or `result === null`.

### Why Top Candidates Shows EXPERIMENTING + VALIDATED

**Rationale:**
- `EXPERIMENTING`: Actively being validated (top priority)
- `VALIDATED`: Ready to build (next priority)
- These are the ideas that need attention or are ready to execute

---

## Common User Scenarios

### Scenario 1: "I moved an idea to EXPERIMENTING but Active Experiments is still 0"

**Explanation:** Moving to `EXPERIMENTING` only changes state. Experiments must be created separately.

**Solution:** Click "Run experiment loop" to automatically create experiments for ideas in `EXPERIMENTING` state.

### Scenario 2: "Why did my idea automatically move to KILLED?"

**Explanation:** Idea failed one or more hard filters during auto-scoring.

**Check:** Look at idea's filter statuses:
- `passesMarket`: ARPU too low?
- `passesRegulation`: In excluded domain?
- `passesAgentFit`: Marked as manual work heavy?
- `passesFounderFit`: Missing founder fit signal?

### Scenario 3: "My idea has experiments but isn't VALIDATED"

**Explanation:** Validation requires:
- All experiments `PASSED`
- At least 2 experiments
- At least one experiment of type `AGENT_OWNERSHIP`

**Check:** Review experiment results and types.

---

## Configuration

### Idea Intent Config (L3)

Located in `src/l3/ideasIntent.ts` and database table `IdeaIntentConfig`.

**Key Settings:**
- `arpuFloor`: Minimum ARPU to pass market filter (default: $50)
- `excludedDomains`: Domains to exclude (default: medical, securities, gambling)
- `founderStrengths`: Founder's strengths (default: gtm, ops, partnerships)
- `agentFitKeywords`: Keywords that indicate agent fit (default: inbox, email, CRM, ticket, document, schedule, summary)
- `minScoreForExperiment`: Minimum total score to move to EXPERIMENTING (default: 9)

**Signal Sources:**
- Configured in `DEFAULT_IDEA_SOURCES`
- Includes LinkedIn job searches, Reddit scraping, G2 reviews
- Can be extended via Feedly or Apify sources

### LLM Configuration (for Experiment Interpretation)

**Environment Variables:**
- `OPENAI_API_KEY`: OpenAI API key (uses `gpt-4o-mini` by default)
- `ANTHROPIC_API_KEY`: Anthropic API key (uses `claude-3-5-sonnet-20241022` by default)

**Programmatic Configuration:**
```typescript
import { configureLLM } from '@/lib/llm';

configureLLM({
  provider: 'openai', // or 'anthropic'
  apiKey: 'sk-...',
  model: 'gpt-4o-mini', // optional, model name
  temperature: 0.3 // optional, lower = more deterministic
});
```

**Behavior:**
- If API key is set: Uses LLM for intelligent experiment interpretation
- If no API key: Automatically falls back to keyword-based interpretation
- System works in both modes - no breaking changes

---

## Appendix: State Transition Diagram

```
                    ┌─────────────┐
                    │ PENDING_REVIEW │
                    └──────┬───────┘
                           │
                           ▼
                    ┌─────────────┐
                    │   BACKLOG    │◄─────┐
                    └──────┬───────┘      │
                           │              │
                           ▼              │
                    ┌─────────────┐      │
                    │   SCORING    │──────┘
                    └──────┬───────┘
                           │
        ┌──────────────────┼──────────────────┐
        │                  │                  │
        ▼                  ▼                  ▼
   ┌─────────┐      ┌──────────────┐   ┌─────────┐
   │ KILLED  │      │ EXPERIMENTING │   │SCORING  │
   └─────────┘      └──────┬───────┘   └─────────┘
                            │
                            ▼
                     ┌──────────────┐
                     │  VALIDATED    │
                     └───────────────┘

Manual transitions: Any state → Any state (via drag-drop or dropdown)
Auto transitions: Based on filters/scores/experiment results
```

---

**Last Updated:** Updated to reflect LLM-based experiment interpretation (with keyword fallback)
**Maintained By:** Should be updated when business logic changes

